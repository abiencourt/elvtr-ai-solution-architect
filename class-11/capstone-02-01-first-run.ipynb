{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ede245-8bd8-4ca3-8922-c3b725ba05ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "# AISA Capstone 2 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc35067-b7cf-438c-81ff-1eb4ed6a9725",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook provides an environment for you to build your intuition on the steps to take when developing a high quality Retrieval Augmented Generation (RAG) solution. \n",
    "RAG solutions retrieve data before calling the large language model (LLM) to generate an answer. \n",
    "The retrieved data is used to augment the prompt to the LLM by adding the relevant retrieved data in context. \n",
    "Any RAG solution is only as good as the quality of the data retrieval process, and this is the particular focus of this notebook, and the accompanying questions and tasks.\n",
    "\n",
    "The RAG solution developed here is enabled by the Llamaindex framework. This is a popular framework in the industry for developing RAG and Agent based solutions. In addition to providing a core set of tools for orchestration of RAG and Agent workflows, there is broad integration with a variety of platforms for model inference (LLM, embedding, ...), and, importantly, tooling for solution evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e4d6f9-7cc1-416b-b035-8403ca7bc8f0",
   "metadata": {},
   "source": [
    "## Prerequisites for running the notebook\n",
    "- That you have granted access to the Bedrock models that you are going to use, in the region (**us-west-2**) where you are going to use Bedrock - \n",
    "[reference](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access-modify.html)\n",
    "- Your SageMakerExecutionRole has permissions to invoke Bedrock models - \n",
    "[reference](https://docs.aws.amazon.com/bedrock/latest/userguide/inference-prereq.html)\n",
    "- This notebook has been tested with SageMaker Notebook Instance running a `conda_python3` kernel\n",
    "- The AWS region set for Amazon Bedrock use, needs to be in a region where the models being used are 1/ available, and 2/ enabled for use. This notebook was tested with Bedrock region `us-west-2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5514f985-a013-48e9-acd9-73d4eeb137f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Implementation\n",
    "This notebook uses llamaindex to define and execute the RAG solution. We will be using the following tools:\n",
    "\n",
    "- **LLM (Large Language Model)**: e.g. Anthropic Claude Haiku available through Amazon Bedrock\n",
    "\n",
    "  LLMs are used in the notebook for 1/ RAG response generation, to show the overall RAG workflow in actions, and 2/ for generating test questions on the indexed content (llamaindex nodes) for retrieval evaluation.\n",
    "  \n",
    "- **Text Embeddings Model**: e.g. Amazon Titan Embeddings available through Amazon Bedrock\n",
    "\n",
    "  This embedding model is used to generate semantic vector representations of the content (llamaindex nodes) to be stored and the questions input to the RAG solution.\n",
    "  \n",
    "- **Document Loader**: SimpleDirectoryReader (Llamaindex)\n",
    "\n",
    "  Before your chosen LLM can act on your data you need to load it. The way LlamaIndex does this is via data connectors, also called 'Reader'. Data connectors ingest data from different data sources and format the data into Document objects. A Document is a collection of data (currently text, and in future, images and audio) and metadata about that data.\n",
    "  \n",
    "  This implementation use SimpleDirectoryReader, which creates documents out of every file in a given directory. It can read a variety of formats including Markdown, PDFs, Word documents, and PowerPoint decks.\n",
    "\n",
    "- **Vector Store**: VectorIndex (Llamaindex)\n",
    "\n",
    "  In this notebook we are using this in-memory vector-store to store both the embeddings and the documents. In an enterprise context this could be replaced with a persistent store such as AWS OpenSearch, RDS Postgres with pgVector, ChromaDB, Pinecone or Weaviate.\n",
    "  \n",
    "  LlamaIndex abstracts the underlying vector database storage implementation with a VectorIndex class. This warps the Index, which is a data structure composed of Document objects, designed to enable querying by an LLM. The Index is designed to be complementary to your querying strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbe5196-2edf-4f54-be53-12bc4d70e3ea",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da34a35-29ee-4c26-8398-7e1bfe7c58f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d293136b-753b-4774-95bc-cd965a38b13f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Install required Python modules for constructing the RAG solution.\n",
    "You only need to run this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98c358c2-f00d-4582-867a-1ae49bfa9354",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.12.19)\n",
      "Requirement already satisfied: llama-index-llms-bedrock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.3.3)\n",
      "Requirement already satisfied: llama-index-embeddings-bedrock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index) (0.4.6)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index) (0.12.19)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index) (0.6.7)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index) (0.3.20)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index) (0.4.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index) (0.4.5)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.34.26 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-llms-bedrock) (1.36.1)\n",
      "Requirement already satisfied: llama-index-llms-anthropic<0.7.0,>=0.6.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-llms-bedrock) (0.6.5)\n",
      "Requirement already satisfied: aioboto3<14.0.0,>=13.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-embeddings-bedrock) (13.4.0)\n",
      "Requirement already satisfied: aiobotocore==2.18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiobotocore[boto3]==2.18.0->aioboto3<14.0.0,>=13.1.1->llama-index-embeddings-bedrock) (2.18.0)\n",
      "Requirement already satisfied: aiofiles>=23.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aioboto3<14.0.0,>=13.1.1->llama-index-embeddings-bedrock) (24.1.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiobotocore==2.18.0->aiobotocore[boto3]==2.18.0->aioboto3<14.0.0,>=13.1.1->llama-index-embeddings-bedrock) (3.11.11)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiobotocore==2.18.0->aiobotocore[boto3]==2.18.0->aioboto3<14.0.0,>=13.1.1->llama-index-embeddings-bedrock) (0.12.0)\n",
      "Requirement already satisfied: botocore<1.36.2,>=1.36.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiobotocore==2.18.0->aiobotocore[boto3]==2.18.0->aioboto3<14.0.0,>=13.1.1->llama-index-embeddings-bedrock) (1.36.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiobotocore==2.18.0->aiobotocore[boto3]==2.18.0->aioboto3<14.0.0,>=13.1.1->llama-index-embeddings-bedrock) (2.9.0.post0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiobotocore==2.18.0->aiobotocore[boto3]==2.18.0->aioboto3<14.0.0,>=13.1.1->llama-index-embeddings-bedrock) (1.0.1)\n",
      "Requirement already satisfied: multidict<7.0.0,>=6.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiobotocore==2.18.0->aiobotocore[boto3]==2.18.0->aioboto3<14.0.0,>=13.1.1->llama-index-embeddings-bedrock) (6.1.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiobotocore==2.18.0->aiobotocore[boto3]==2.18.0->aioboto3<14.0.0,>=13.1.1->llama-index-embeddings-bedrock) (2.3.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiobotocore==2.18.0->aiobotocore[boto3]==2.18.0->aioboto3<14.0.0,>=13.1.1->llama-index-embeddings-bedrock) (1.17.2)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0.0,>=1.34.26->llama-index-llms-bedrock) (0.11.2)\n",
      "Requirement already satisfied: openai>=1.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.63.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.19->llama-index) (2.0.37)\n",
      "Requirement already satisfied: dataclasses-json in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (2025.2.0)\n",
      "Requirement already satisfied: httpx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (3.4)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (2.10.6)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (0.9.0)\n",
      "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.12)\n",
      "Requirement already satisfied: anthropic>=0.41.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic[bedrock,vertex]>=0.41.0->llama-index-llms-anthropic<0.7.0,>=0.6.3->llama-index-llms-bedrock) (0.46.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.2)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.5.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.3.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.18.0->aiobotocore[boto3]==2.18.0->aioboto3<14.0.0,>=13.1.1->llama-index-embeddings-bedrock) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.18.0->aiobotocore[boto3]==2.18.0->aioboto3<14.0.0,>=13.1.1->llama-index-embeddings-bedrock) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.18.0->aiobotocore[boto3]==2.18.0->aioboto3<14.0.0,>=13.1.1->llama-index-embeddings-bedrock) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.18.0->aiobotocore[boto3]==2.18.0->aioboto3<14.0.0,>=13.1.1->llama-index-embeddings-bedrock) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.18.0->aiobotocore[boto3]==2.18.0->aioboto3<14.0.0,>=13.1.1->llama-index-embeddings-bedrock) (1.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.18.0->aiobotocore[boto3]==2.18.0->aioboto3<14.0.0,>=13.1.1->llama-index-embeddings-bedrock) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.18.0->aiobotocore[boto3]==2.18.0->aioboto3<14.0.0,>=13.1.1->llama-index-embeddings-bedrock) (1.18.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic>=0.41.0->anthropic[bedrock,vertex]>=0.41.0->llama-index-llms-anthropic<0.7.0,>=0.6.3->llama-index-llms-bedrock) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic>=0.41.0->anthropic[bedrock,vertex]>=0.41.0->llama-index-llms-anthropic<0.7.0,>=0.6.3->llama-index-llms-bedrock) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic>=0.41.0->anthropic[bedrock,vertex]>=0.41.0->llama-index-llms-anthropic<0.7.0,>=0.6.3->llama-index-llms-bedrock) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic>=0.41.0->anthropic[bedrock,vertex]>=0.41.0->llama-index-llms-anthropic<0.7.0,>=0.6.3->llama-index-llms-bedrock) (1.3.1)\n",
      "Requirement already satisfied: google-auth<3,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic[bedrock,vertex]>=0.41.0->llama-index-llms-anthropic<0.7.0,>=0.6.3->llama-index-llms-bedrock) (2.38.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.5)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.19->llama-index) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.19->llama-index) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.19->llama-index) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.19->llama-index) (0.14.0)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.19->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.19->llama-index) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.19->llama-index) (3.4.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.19->llama-index) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.19->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.19->llama-index) (3.26.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic>=0.41.0->anthropic[bedrock,vertex]>=0.41.0->llama-index-llms-anthropic<0.7.0,>=0.6.3->llama-index-llms-bedrock) (1.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth<3,>=2->anthropic[bedrock,vertex]>=0.41.0->llama-index-llms-anthropic<0.7.0,>=0.6.3->llama-index-llms-bedrock) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth<3,>=2->anthropic[bedrock,vertex]>=0.41.0->llama-index-llms-anthropic<0.7.0,>=0.6.3->llama-index-llms-bedrock) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth<3,>=2->anthropic[bedrock,vertex]>=0.41.0->llama-index-llms-anthropic<0.7.0,>=0.6.3->llama-index-llms-bedrock) (4.7.2)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-cloud-services>=0.6.1->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.19->llama-index) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->aiobotocore==2.18.0->aiobotocore[boto3]==2.18.0->aioboto3<14.0.0,>=13.1.1->llama-index-embeddings-bedrock) (1.17.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.19->llama-index) (3.2.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=2->anthropic[bedrock,vertex]>=0.41.0->llama-index-llms-anthropic<0.7.0,>=0.6.3->llama-index-llms-bedrock) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \\\n",
    "    llama-index \\\n",
    "    llama-index-llms-bedrock \\\n",
    "    llama-index-embeddings-bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c724a2d-6686-4177-baa1-3fed868170d5",
   "metadata": {},
   "source": [
    "Download the default RAG test source data to our target source_docs directory. \n",
    "You only need to run this once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5190bed5-26d3-4897-a270-74087c9af1ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_docs_dir = './source_docs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d14fc8-2f54-4a24-9ad4-9e84678e9495",
   "metadata": {
    "tags": []
   },
   "source": [
    "The following creates the source_docs directory and downloads a document to that directory. The contents of this directory, \n",
    "initially the document that is downloaded here, will be used in the steps that follow.\n",
    "\n",
    "After running this notebook in its entirity and reviewing its operation, delete this content and add your own content to the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886e9c7c-3e23-40ba-a7c1-b852d083aa7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-02-19 14:51:22--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75042 (73K) [text/plain]\n",
      "Saving to: ‘./source_docs//paul_graham_essay.txt’\n",
      "\n",
      "100%[======================================>] 75,042      --.-K/s   in 0.002s  \n",
      "\n",
      "2025-02-19 14:51:22 (43.1 MB/s) - ‘./source_docs//paul_graham_essay.txt’ saved [75042/75042]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download and load data\n",
    "!mkdir -p {source_docs_dir}\n",
    "!wget --no-check-certificate 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O {source_docs_dir}'/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ab5b10-dcb8-423c-b1ef-d39a656f6b41",
   "metadata": {
    "tags": []
   },
   "source": [
    "Import auxilliarty modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f69ef6-0453-465f-adc0-3180b7f41352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import boto3  # AWS SDK for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f65d3264-223c-4902-8e21-6886e25a52b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is required when running within a jupyter notebook, otherwise you will get errors when llamaindex modules run\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b618759-983d-4d7e-8bf6-840b355b5609",
   "metadata": {},
   "source": [
    "Import required Python modules for constructing and evaluating the RAG solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5025ceaf-9699-43ba-9369-773612652b4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.bedrock import BedrockEmbedding\n",
    "from llama_index.llms.bedrock import Bedrock\n",
    "\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.extractors import TitleExtractor\n",
    "from llama_index.core.ingestion import IngestionPipeline, IngestionCache\n",
    "from llama_index.core.text_splitter import TokenTextSplitter\n",
    "\n",
    "\n",
    "from llama_index.core.evaluation import (\n",
    "    DatasetGenerator,\n",
    "    RetrieverEvaluator,\n",
    "    generate_question_context_pairs,\n",
    ")\n",
    "\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    Response,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d66520-b9b5-4fdc-a00b-45d23734bfdb",
   "metadata": {},
   "source": [
    "## Configure the models that will be used for the RAG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05b8643-0fc7-4984-bfb4-820b92ce0e99",
   "metadata": {},
   "source": [
    "**Note**: By default this notebook with use the `us-west-2` region. This region has support for the models used in this notebook. You should not need to change this setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c946049d-010b-4485-83ce-08425c254261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AWS_REGION = \"us-west-2\"\n",
    "AWS_REGION = \"us-east-1\"  # this is an alternative setting to use if desired "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3a6109-6dba-4312-951a-af27765774b3",
   "metadata": {},
   "source": [
    "Define the set of Bedrock model IDs that we that we'll use when developing and testing our solution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d8d3b8-0a47-45db-9b2f-3265d0c795f0",
   "metadata": {},
   "source": [
    "Establish a connection to the Amazon Bedrock service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "614ca8a1-d4b7-463e-8770-76bf83a37246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boto3_bedrock = boto3.client(\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d038da-c7fb-4c07-957c-c23a1effe13e",
   "metadata": {},
   "source": [
    "### Configure the target embeddings models for use with Llamaindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbf2a047-82b9-4ee9-bbcc-4ab33d9a07f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titan_text_embeddings_multilingual_v1_id = \"amazon.titan-embed-text-v1\"\n",
    "titan_text_embeddings_multilingual_v2_id = \"amazon.titan-embed-text-v2:0\"\n",
    "cohere_text_embeddings_english_id = \"cohere.embed-english-v3\"\n",
    "cohere_text_embeddings_multilingual_id = \"cohere.embed-multilingual-v3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942ca6ba-721d-4af6-a25f-0026218373c5",
   "metadata": {},
   "source": [
    "Configure our chosen embeddings model for use with llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eac101f7-1f62-4720-9a94-64bdce9102de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titan_text_embeddings_v2 = BedrockEmbedding(model=titan_text_embeddings_multilingual_v2_id,region_name=AWS_REGION)\n",
    "titan_text_embeddings_v1 = BedrockEmbedding(model=titan_text_embeddings_multilingual_v1_id,region_name=AWS_REGION)\n",
    "cohere_text_embeddings_english = BedrockEmbedding(model=cohere_text_embeddings_english_id,region_name=AWS_REGION)\n",
    "cohere_text_embeddings_multilingual= BedrockEmbedding(model=cohere_text_embeddings_english_id,region_name=AWS_REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac963474-ee9e-47f4-ae7f-5896b3ee805d",
   "metadata": {},
   "source": [
    "### Configure the target LLMs for use with Llamaindex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb66fcc-a3c2-4acd-9004-53d96c083391",
   "metadata": {
    "tags": []
   },
   "source": [
    "The following Mistral models produce good questions for evaluation. The Titan model produces questions of lesser quality \n",
    "and sometimes not in the format needed by the tools. \n",
    "\n",
    "**Note** Most Bedrock LLMs do note produce questions in a format that can be directly used for evaluation with the tooling as it is configured in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3d60343-0fad-4fad-a6a0-1a28a60c5539",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruct_mistral7b_id = \"mistral.mistral-7b-instruct-v0:2\"\n",
    "instruct_mixtral8x7b_id=\"mistral.mixtral-8x7b-instruct-v0:1\"\n",
    "titan_text_express_id = \"amazon.titan-text-express-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad66c9c9-752f-425c-b783-c5951c47d95c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the parameters to be applied when invoking the model\n",
    "model_kwargs_llm = {\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_p\": 0.9,\n",
    "    \"top_k\": 200,\n",
    "    \"max_tokens\": 4096\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7223cc97-dc5b-40f4-8acb-92be61e03885",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_mistral7b = Bedrock(model=instruct_mistral7b_id, client=boto3_bedrock, model_kwargs=model_kwargs_llm, region_name=AWS_REGION)\n",
    "llm_mixtral8x7b = Bedrock(model=instruct_mixtral8x7b_id, client=boto3_bedrock, model_kwargs=model_kwargs_llm, region_name=AWS_REGION)\n",
    "llm_titan_express = Bedrock(model=titan_text_express_id, client=boto3_bedrock, model_kwargs=model_kwargs_llm, region_name=AWS_REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6babd1c3-cc16-4914-ba7a-83185c56a418",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use the following cell to configure the embeddings model to use for the cells that follow\n",
    "\n",
    "The embeddings model is a critical choice for the accuracy of your RAG solution.\n",
    "Experiment with the options here to see which is best for your content.\n",
    "If you want more, test with further alternatives. There are many that are readily supported by llama_index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f52d75b4-f9ef-4398-9214-15920b917ff6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KEY CELL 01\n",
    "\n",
    "embed_model = titan_text_embeddings_v1\n",
    "# embed_model = titan_text_embeddings_v2\n",
    "# embed_model = cohere_text_embeddings_english\n",
    "# embed_model = cohere_text_embeddings_multilingual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf70d0f7-6744-41e8-a62b-8f5624fe54f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use the following cell to configure the LLM to use for the cells that follow\n",
    "The LLM will be used for question generation and RAG answer generation in this notebook as it is currently configured.\n",
    "The default value llm_mistral7b works well with the code and should be used if possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82ea65f7-1428-41c0-850d-c1eb176c41e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_model = llm_mistral7b\n",
    "# llm_model = llm_mixtral8x7b\n",
    "# llm_model = llm_titan_express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58bbe67d-5908-4d3f-8c0a-831391a4ad5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set LlamaIndex default model settings to what was set in the cells above\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46229098-ce14-4834-a863-2035547a53ab",
   "metadata": {},
   "source": [
    "## Read in the documents for adding to our data store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674fc1fd-f34b-41a1-9d88-e4647a521273",
   "metadata": {},
   "source": [
    "Read in the documents in the 'data/source_docs' directory into a structure ready for use by llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "486bd6d1-2454-45ff-a33e-fcbf3ea77867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(source_docs_dir)\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b952f0-8f8a-4920-ad35-e8abe08fc429",
   "metadata": {},
   "source": [
    "Quick check here to see that all of your documents were read. The count should match the number of pages in the documents in source_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "752782ee-1d5c-41d7-8266-c1a6c9194a7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a261170a-c9db-4f59-b391-9e5039397e26",
   "metadata": {},
   "source": [
    "## Create and run the document ingestion pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4a1fda-bc75-42a1-be1b-54c29a624abc",
   "metadata": {
    "tags": []
   },
   "source": [
    "The following cell defines two different document ingestion pipelines. \n",
    "If you have time, test using both of these, and create you own and test with that also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "773aa337-a276-441a-92be-190a2d9f37e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define two transformation for the ingestion pipelines for initial experimentation\n",
    "\n",
    "transformations_00=[\n",
    "        TokenTextSplitter(separator=\" \", chunk_size=512, chunk_overlap=100),\n",
    "        embed_model,\n",
    "    ]\n",
    "\n",
    "transformations_01=[\n",
    "        SentenceSplitter(chunk_size=512, chunk_overlap=100),\n",
    "        TitleExtractor(),\n",
    "        embed_model,\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1b013b-f07e-441d-8396-dab15325e7d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use the following cell to configure the data ingestion pipeline for processing the source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7134f8fb-03eb-4167-9063-4fcd08ed7643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KEY CELL 02\n",
    "\n",
    "# create the pipeline with one of the transformation configurations defined above\n",
    "\n",
    "pipeline = IngestionPipeline(transformations=transformations_00)\n",
    "# pipeline = IngestionPipeline(transformations=transformations_01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4314c658-de88-432b-98bc-08a5ccf7bee6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run the configured ingestion pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96c6cf10-0dcc-40eb-a659-3b70cfb4a939",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes: 44\n"
     ]
    }
   ],
   "source": [
    "# run the pipeline\n",
    "nodes = pipeline.run(documents=documents)\n",
    "print(f\"number of nodes: {len(nodes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3331bd97-75af-432b-a77c-a82be092585d",
   "metadata": {
    "tags": []
   },
   "source": [
    "This may make test analysis easier. It is none essential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b464f0b-b123-4a12-b85f-8718fcaee4bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# By default, the node ids are set to random uuids. \n",
    "# To ensure same id's per run, we manually set them to consistent sequential numbers.\n",
    "for idx, node in enumerate(nodes):\n",
    "    node.id_ = f\"node_{idx}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cffb0df-bf84-4630-87b0-ba8fae23f461",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1701388955116272, -0.23478008806705475, -0.08697916567325592, -0.028327545151114464, 0.6199652552604675, -0.1631365716457367, -0.27135413885116577, 0.0008344720699824393, -0.011516204103827477, 0.08718894422054291, -0.004535590298473835, 0.19147858023643494, 0.131626158952713, 0.24182581901550293, 0.07359664887189865, 0.14907407760620117, 0.14453125, 0.47193285822868347, -0.293070912361145, 0.006018519401550293, -0.09528356045484543, 0.2752821147441864, -0.17750290036201477, 0.03931206464767456, -0.016977719962596893, 0.03742766007781029, -0.06696686893701553, -0.08252314478158951, 0.008521411567926407, 0.1655237227678299, -0.31513309478759766, 0.1688946783542633, 0.16609518229961395, -0.11681133508682251, -0.11134259402751923, -0.2849247455596924, 0.023553241044282913, 0.061834488064050674, 0.47647568583488464, -0.13562282919883728, 0.16093748807907104, 0.12187500298023224, -0.2752893567085266, -0.49947917461395264, -0.07238136976957321, 0.12523147463798523, -0.01371527649462223, -0.3404025733470917, 0.05991211161017418, 0.05108506977558136, 0.18008536100387573, -0.020023148506879807, 0.015899885445833206, 0.2727430462837219, 0.09301938116550446, -0.35444876551628113, -0.05514729768037796, -0.20656828582286835, -0.6109375357627869, -0.319525808095932, -0.21280381083488464, -0.15924116969108582, 0.1660228669643402, 0.3897877037525177, -0.015596065670251846, -0.04830729216337204, -0.1234230324625969, 0.08993054926395416, 0.19195601344108582, -0.11292678862810135, 0.2654224634170532, -0.2154441475868225, 0.30368924140930176, 0.24537035822868347, -0.12688800692558289, 0.02254774235188961, -0.05590277910232544, -0.10879629105329514, 0.09615884721279144, 0.0564236119389534, 0.2582465410232544, 0.09576099365949631, -0.18621237576007843, -0.13925057649612427, -0.06707175821065903, 0.010181567631661892, -0.27803096175193787, 0.07043185830116272, 0.0001341219322057441, -0.12566551566123962, 0.050245948135852814, 0.15936052799224854, -0.07818286865949631, 0.05998263508081436, 0.058087386190891266, 0.22643952071666718, 0.04149305820465088, -0.1621600091457367, 0.2907407581806183, 0.10869502276182175, 0.013071469031274319, 0.06232638657093048, 0.0963541641831398, -0.07219328731298447, -0.11935040354728699, 0.06736110895872116, 0.051135703921318054, 0.1819661408662796, 0.051208946853876114, 0.36487266421318054, -0.13446179032325745, -0.15633679926395416, 0.004745369777083397, -0.17643952369689941, -0.2751085162162781, -0.03810764104127884, -0.04160337150096893, 0.07907985895872116, -0.019187644124031067, 0.05435474216938019, -0.006546585354954004, 0.13940972089767456, 0.273017942905426, 0.2535156309604645, -0.10321180522441864, 0.31828704476356506, 0.18682001531124115, 0.1328703612089157, 0.11443865299224854, -0.028110530227422714, 0.20596064627170563, 0.0401475690305233, 0.1983506977558136, -0.12703992426395416, 0.17663347721099854, 0.04531249776482582, -0.07687897235155106, -0.2746961712837219, 0.2637767791748047, 0.17526040971279144, -0.1015046238899231, 0.27642324566841125, 0.2699073851108551, 0.0735677033662796, 0.0712384283542633, 0.11910083889961243, -0.0014576101675629616, -0.18550346791744232, -0.09697627276182175, -0.3857114613056183, -0.10387007892131805, 0.266391783952713, -0.13343459367752075, -0.04299045354127884, -0.24260705709457397, -0.15541088581085205, 0.13561920821666718, 0.19539929926395416, -0.39304107427597046, 0.5300636291503906, 0.08153935521841049, 0.04444444179534912, -0.14704860746860504, -0.14060330390930176, -0.2525463104248047, -0.25572916865348816, 0.07439416646957397, 0.14939597249031067, -0.28078705072402954, -0.3810329735279083, -0.1391637623310089, -0.3066026270389557, -0.2644241750240326, -0.0049913190305233, 0.21504990756511688, 0.010083911940455437, -0.13032406568527222, -0.1904875487089157, 0.3622667193412781, 0.030374709516763687, -0.08514178544282913, 0.1832609921693802, 0.025484664365649223, -0.3182743787765503, 0.2688367962837219, 0.04477719962596893, 0.08236400038003922, 0.1780092567205429, -0.07847221940755844, 0.20331308245658875, 0.14225983619689941, -0.2108525037765503, 0.08326099067926407, -0.2537326216697693, 0.21778066456317902, 0.059953704476356506, 0.1095920130610466, -0.11208043992519379, -0.11543691903352737, 0.08112340420484543, -0.09864004701375961, -0.12173755466938019, -0.24655672907829285, -0.0032986109144985676, 0.016908999532461166, 0.037615738809108734, -0.059859663248062134, -0.23791955411434174, 0.12676504254341125, 0.007342303637415171, -0.07165798544883728, 0.31980612874031067, -0.1605902761220932, -0.1685691475868225, -0.2151692658662796, 0.42228731513023376, 0.07381365448236465, -0.0001736115664243698, -0.34074074029922485, 0.23704425990581512, 0.11207320541143417, 0.09768518805503845, -0.3679470419883728, 0.09649884700775146, -0.3428240716457367, -0.0032986109144985676, -0.23517072200775146, -0.13480810821056366, -0.05674189329147339, 0.11882234364748001, -0.14789654314517975, 0.13760127127170563, 0.3548755943775177, 0.16397568583488464, 0.10176505148410797, -0.02135416679084301, -0.15284287929534912, -0.04674840718507767, -0.12730035185813904, 0.03706597164273262, -0.14008969068527222, 0.1299334466457367, -0.25408709049224854, -0.33368054032325745, -0.1665075123310089, 0.17348089814186096, 0.053315337747335434, 0.22647568583488464, -0.21270254254341125, -0.040393516421318054, 0.1614583283662796, 0.01647135429084301, -0.337890625, 0.29083725810050964, -0.3300202488899231, -0.17743055522441864, -0.2120804339647293, -0.3280816078186035, 0.026283999904990196, 0.1899450272321701, 0.2567708194255829, 0.05451388657093048, 0.012373408302664757, 0.16810618340969086, -0.04032117873430252, -0.17864583432674408, 0.2425130158662796, -0.015762440860271454, 0.035619210451841354, -0.05182291939854622, 0.00013116553600411862, -0.22735820710659027, 0.23506943881511688, -0.11104600131511688, 0.016583478078246117, -0.09710647165775299, 0.12341037392616272, 0.357089102268219, 0.4234953820705414, -0.020153354853391647, 0.23666086792945862, -0.043214697390794754, 0.2000289261341095, -0.0890263244509697, -0.11937210708856583, -0.43964117765426636, 0.4102068543434143, 0.10546875, 0.08913121372461319, -0.02482638880610466, -0.09560184925794601, 0.009845196269452572, 0.15985241532325745, -0.33987268805503845, 0.2657262682914734, -0.04334490746259689, -0.007175926119089127, -0.08800636231899261, 0.062355320900678635, 0.044541195034980774, -0.07107928395271301, 0.03737973794341087, 0.059620946645736694, -0.05695891007781029, 0.30478155612945557, -0.03864293918013573, -0.1832682341337204, -0.004354745615273714, 0.10855034738779068, -0.08553241193294525, -0.20782697200775146, 0.2747468054294586, -0.23142360150814056, 0.03441840037703514, -0.11754557490348816, 0.10511429607868195, 0.18735532462596893, 0.09044776856899261, -0.11540798097848892, -0.2748914659023285, -0.2508101761341095, -0.31039902567863464, -0.13521501421928406, -0.396151602268219, 0.27340856194496155, -0.08145254850387573, -0.1906539350748062, -0.051770471036434174, -0.24156177043914795, 0.042390044778585434, 0.20537470281124115, -0.21747684478759766, 0.2757059931755066, 0.14846190810203552, 0.3114149272441864, -0.19947916269302368, 0.21289785206317902, 0.27199074625968933, -0.0906575545668602, -0.22664931416511536, -0.01174045167863369, -0.20081017911434174, 0.01805555447936058, -0.22439958155155182, -0.05072428286075592, 0.29694733023643494, -0.0636393204331398, 0.008823422715067863, 0.04262152686715126, 0.16345486044883728, 0.24578993022441864, -0.29793837666511536, 0.14392361044883728, 0.036624711006879807, 0.15882523357868195, -0.12287326902151108, -0.0025426794309169054, -0.050723377615213394, -0.47994789481163025, -0.16996526718139648, 0.2939525544643402, 0.11993678659200668, -0.2736147344112396, -0.21773725748062134, 0.04346064478158951, -0.17793691158294678, -0.26490160822868347, -0.5201388597488403, -0.012094907462596893, -0.07591868937015533, -0.34014755487442017, 0.27285879850387573, -0.01612413115799427, -0.1142071783542633, 0.016196470707654953, -0.11908275634050369, -0.14673031866550446, 0.28654512763023376, -0.05286458507180214, 0.2039424180984497, -0.19730903208255768, -0.09360532462596893, -0.46449652314186096, -0.14644096791744232, 0.06367910653352737, -0.07962962985038757, -0.19262151420116425, 0.049623843282461166, 0.1658465415239334, 0.016196468845009804, -0.04607204720377922, 0.13988715410232544, -0.2905381917953491, -0.4604890048503876, 0.09885706007480621, -0.09643825143575668, -0.0029405381064862013, 0.22453702986240387, 0.4179217219352722, 0.08153211325407028, -0.23389755189418793, 0.24335937201976776, 0.19690394401550293, -0.17641782760620117, -0.2065022736787796, 0.04517234489321709, 0.24238280951976776, -0.19684606790542603, 0.2592881917953491, -0.0855034738779068, -0.4996238350868225, -0.20829716324806213, 0.09463975578546524, 0.3698929250240326, -0.23939526081085205, 0.019288916140794754, -0.2512623071670532, 0.09690393507480621, -0.1449110209941864, 0.28252315521240234, -0.10159143805503845, -0.09728008508682251, 0.28430265188217163, 0.15474537014961243, -0.44594907760620117, 0.15143229067325592, 0.01484375074505806, -0.27698206901550293, -0.1915861964225769, 0.012774883769452572, -0.0836082175374031, 0.2866319417953491, 0.06732494384050369, -0.26022857427597046, -0.015647605061531067, 0.34486398100852966, 0.518417239189148, 0.21480034291744232, -0.16778066754341125, 0.01605902798473835, -0.020934605970978737, 0.3825303912162781, -0.2553819417953491, -0.0735098347067833, -0.17254050076007843, 0.08090277016162872, -0.11515481024980545, 0.060271989554166794, -0.24638308584690094, 0.1457754671573639, 0.17025461792945862, 0.26549479365348816, 0.1315610408782959, -0.27980324625968933, 0.033232059329748154, -0.2521701455116272, -0.0485026054084301, -0.17710503935813904, 0.5457175970077515, -0.17641058564186096, 0.04201569780707359, -0.18524304032325745, -0.15954861044883728, 0.028920717537403107, -0.07590784132480621, -0.057588253170251846, 0.5254051089286804, -0.16320890188217163, 0.10040508955717087, -0.30101272463798523, -0.3285156190395355, -0.014525461941957474, -0.10529513657093048, -0.1301070600748062, -0.0007089115679264069, -0.06824363023042679, -0.05247124284505844, -0.06261935830116272, 0.09406828135251999, -0.5, 0.21280381083488464, 0.04567418992519379, -0.1929217278957367, 0.03825231269001961, 0.08188657462596893, 0.3150028884410858, 0.06934317201375961, -0.06492693722248077, -0.01610242947936058, 0.23879483342170715, 0.03191550821065903, 0.2006637006998062, -0.16054686903953552, -0.034851524978876114, -0.1099681705236435, 0.06666666269302368, -0.0003383707953616977, 0.011223234236240387, 0.32387152314186096, -0.10293692350387573, -0.19287832081317902, -0.0287543386220932, 0.04140624776482582, 0.49655669927597046, 0.06783854216337204, 0.2372576743364334, -0.03634259104728699, -0.024247683584690094, -0.06494140625, -0.21643517911434174, -0.1452835500240326, 0.3387225270271301, -0.07808160036802292, 0.0358072891831398, 0.24957320094108582, 0.08942418545484543, 0.006119789555668831, -0.1801215261220932, -0.24783708155155182, 0.12187500298023224, 0.435127317905426, -0.23852719366550446, 0.17798031866550446, 0.13714554905891418, -0.2639394998550415, 0.242710143327713, 0.2423979490995407, 0.11308594048023224, -0.4130750894546509, -0.12306857109069824, -0.07312282919883728, 0.07489871978759766, -0.03554235398769379, 0.032103586941957474, 0.22682291269302368, 0.136168971657753, 0.032320600003004074, 0.021238425746560097, -0.13706596195697784, -0.13967736065387726, 0.16851669549942017, 0.34117475152015686, -0.31817129254341125, 0.08115234225988388, 0.09963830560445786, -0.3517650365829468, -0.14198856055736542, 0.24595630168914795, -0.09139223396778107, 0.11970485746860504, -0.0012731477618217468, -0.048509836196899414, -0.2990451157093048, -0.31209489703178406, 0.1200629323720932, -0.23339121043682098, -0.04849536716938019, 0.040219906717538834, -0.16346389055252075, -0.2748625576496124, -0.11672453582286835, -0.022923899814486504, -0.21357059478759766, -0.1963668316602707, 0.044343169778585434, -0.16303710639476776, 0.08078703284263611, -0.1983506828546524, -0.3314959406852722, 0.11552372574806213, -0.003240741789340973, -0.2023148089647293, -0.0930682122707367, 0.22315627336502075, 0.3197771906852722, 0.013925056904554367, -0.441840261220932, -0.17921005189418793, 0.24833621084690094, 0.18493923544883728, 0.1394314169883728, 0.13061343133449554, -0.38556134700775146, 0.013043439015746117, 0.13231337070465088, -0.06327763199806213, -0.1151258647441864, -0.2764168977737427, -0.13365161418914795, 0.09797453880310059, 0.13608217239379883, 0.1100260466337204, 0.1183304414153099, 0.14238281548023224, 0.020131655037403107, -0.1577112376689911, -0.022324400022625923, -0.34263598918914795, -0.046969037503004074, -0.6228153705596924, -0.0147569440305233, -0.10271990299224854, 0.0027199089527130127, -0.10515046119689941, -0.009664352051913738, 0.027016419917345047, -0.3848668932914734, -0.08410011231899261, -0.23536603152751923, -0.060749419033527374, -0.050647422671318054, 0.11959996819496155, 0.24849174916744232, -0.015640370547771454, -0.25367477536201477, 0.1084490716457367, 0.2758246660232544, 0.11950954794883728, 0.3690393567085266, 0.1529947966337204, -0.021708622574806213, 0.10400390625, 0.060011573135852814, -0.010966435074806213, 0.12523147463798523, -0.25870949029922485, -0.32891348004341125, -0.31669557094573975, -0.13041087985038757, 0.44322916865348816, 0.11982060223817825, 0.18048322200775146, 0.09105902165174484, -0.06452546268701553, -0.09156538546085358, 0.24508100748062134, 0.037492766976356506, -0.3216037154197693, 0.1851128339767456, 0.06017071753740311, -0.031052879989147186, 0.39484161138534546, 0.15318287909030914, -0.01041666604578495, 0.2079092413187027, -0.19730903208255768, -0.02573784627020359, 0.1379665732383728, 0.05838758870959282, 0.07354239374399185, -0.02259114570915699, -0.04810474440455437, 0.07107928395271301, 0.17673338949680328, -0.17552806437015533, 0.13520869612693787, 0.09932634979486465, 0.1982928216457367, -0.05673104524612427, -0.029651328921318054, -0.204528346657753, 0.055627889931201935, 0.28756240010261536, -0.21089951694011688, 0.016377314925193787, 0.11353442817926407, -0.00516493059694767, -0.022952836006879807, -0.21840277314186096, -0.05457175895571709, 0.11914785951375961, -0.252197265625, 0.12708333134651184, 0.10694263130426407, 0.12547923624515533, -0.16245660185813904, -0.0990089625120163, -0.149623841047287, -0.1762659102678299, -0.15031827986240387, 0.11679687350988388, -0.0873480886220932, -0.06859085708856583, -0.7898871302604675, 0.09503219276666641, 0.10054976493120193, 0.08182870596647263, -0.23579145967960358, -0.05014467239379883, 0.016290508210659027, 0.14367765188217163, 0.16484373807907104, -0.15262585878372192, 0.011577690951526165, 0.14967358112335205, 0.2154947966337204, 0.29071182012557983, 0.007595486007630825, 0.3435329794883728, -0.18425925076007843, 0.12139032781124115, 0.3728877305984497, -0.0037972908467054367, -0.4027343690395355, -0.046263743191957474, 0.5482928156852722, 0.33015045523643494, -0.19752603769302368, 0.26006942987442017, 0.18121382594108582, 0.2247621715068817, 0.001083487062714994, -0.18041087687015533, 0.04149305447936058, 0.0985243022441864, -0.15477430820465088, -0.22961515188217163, 0.021412037312984467, 0.08846932649612427, -0.07442129403352737, -0.177184596657753, -0.34742024540901184, 0.14261972904205322, 0.17608235776424408, 0.013892505317926407, 0.23284867405891418, 0.1059027761220932, 0.06702835857868195, 0.09144964814186096, 0.23574940860271454, -0.21404802799224854, 0.3222511410713196, 0.2910734713077545, 0.16871382296085358, 0.333476185798645, 0.2170717418193817, -0.3445601761341095, 0.07933665812015533, -0.22729672491550446, -0.12615740299224854, -0.12591144442558289, 0.11595775187015533, 0.06481481343507767, 0.28865739703178406, -0.03297887742519379, -0.15775461494922638, 0.032581016421318054, -0.13645832240581512, 0.2514684498310089, 0.27324941754341125, 0.08959056437015533, 0.03729745373129845, 0.12923221290111542, 0.26739004254341125, -0.02138671837747097, 0.17818287014961243, 0.12234339118003845, -0.007067419588565826, 0.050448495894670486, 0.42428383231163025, 0.09258174151182175, 0.01931423507630825, -0.2083912044763565, -0.25951966643333435, -0.15882521867752075, -0.0006781684933230281, -0.4234953820705414, -0.30720484256744385, -0.23799189925193787, 0.18075810372829437, -0.24731534719467163, 0.07922453433275223, -0.17970919609069824, 0.05655381828546524, 0.08642397075891495, 0.07249709963798523, 0.29224535822868347, 0.33883100748062134, -0.19143518805503845, -0.26142939925193787, 0.11863425374031067, 0.25225692987442017, -0.15004339814186096, 0.070203997194767, 0.085069440305233, 0.45054978132247925, 0.1860821694135666, -0.10575810074806213, 0.10037028044462204, 0.33900460600852966, -0.18948206305503845, -0.05622106045484543, 0.14348596334457397, -0.09473017603158951, -0.11937210708856583, 0.3638888895511627, -0.07995695620775223, -0.08932291716337204, 0.08865559101104736, 0.15974391996860504, 0.015075232833623886, -0.15257522463798523, 0.0697699636220932, 0.29306280612945557, 0.05147568881511688, -0.08401330560445786, 0.49936342239379883, 0.04279514029622078, -0.06235532462596893, 0.0569661483168602, -0.2147279977798462, -0.2666594386100769, -0.006568288430571556, 0.02578125149011612, -0.0301649309694767, -0.24867260456085205, 0.22170861065387726, 0.17240305244922638, 0.043692126870155334, 0.052161093801259995, -0.019111689180135727, 0.20428241789340973, -0.19309894740581512, -0.3210214078426361, -0.14128689467906952, 0.0009366070735268295, 0.02491861768066883, 0.07168692350387573, -0.4301454722881317, -0.2452835589647293, 0.06661602854728699, 0.0031647859141230583, 0.12273762375116348, -0.10088387131690979, 0.011979165486991405, -0.0273437462747097, -0.058232057839632034, 0.20853587985038757, 0.05941116809844971, 0.02939452975988388, 0.039731625467538834, -0.150940403342247, -0.3447301685810089, 0.0745949074625969, -0.012167244218289852, -0.11912615597248077, -0.03718171268701553, -0.15769676864147186, -0.11273147910833359, 0.1413339227437973, -0.08692128956317902, -0.1445348560810089, 0.203342005610466, -0.17007377743721008, 0.03943865746259689, -0.31892362236976624, 0.21297742426395416, 0.199978306889534, 0.030439814552664757, -0.016616029664874077, 0.22925347089767456, 0.35526618361473083, 0.0518391914665699, 0.008695023134350777, 0.04146412014961243, 0.13708044588565826, 0.1746961772441864, -0.13692128658294678, 0.11435185372829437, 0.2537326216697693, 0.21740451455116272, -0.07565104216337204, 0.20753037929534912, -0.32061630487442017, 0.2746165990829468, -0.10376156866550446, 0.02517361007630825, 0.03388310223817825, -0.08887442201375961, -0.12736545503139496, 0.17531828582286835, -0.22679398953914642, 0.11028645932674408, 0.0787489116191864, -0.15772569179534912, 0.049019817262887955, 0.6345341205596924, -0.09536313265562057, -0.1056893840432167, -0.15811632573604584, -0.48683086037635803, 0.19929470121860504, -0.11445312201976776, 0.11684389412403107, 0.045081015676259995, 0.10431857407093048, 0.34129050374031067, 0.2835792899131775, -0.21355614066123962, 0.24780091643333435, -0.343192994594574, -0.24403934180736542, -0.2640624940395355, -0.0887586772441864, 0.327358216047287, -0.08524305373430252, -0.07371238619089127, 0.062073204666376114, 0.24125975370407104, 0.06779513508081436, -0.02447916567325592, -0.018400968983769417, 0.08744935691356659, -0.10078124701976776, -0.10119357705116272, 0.35295137763023376, -0.13483795523643494, -0.025202544406056404, -0.1307002305984497, -0.34275171160697937, -0.13215060532093048, -0.15590277314186096, 0.1608072817325592, -0.02990451268851757, 0.05572916567325592, -0.17471358180046082, -0.6151331067085266, 0.3322382867336273, 0.049421295523643494, -0.278544545173645, -0.09884259104728699, 0.004195602610707283, 0.02760416269302368, 0.022410299628973007, -0.04940682649612427, -0.042097076773643494, -0.07165075093507767, 0.22696758806705475, 0.09620948880910873, -0.07523147761821747, 0.0330946147441864, -2.673113704076968e-05, 0.20874565839767456, -0.142795130610466, -0.13723957538604736, 0.04903428629040718, -0.14259259402751923, 0.1267939805984497, -0.16484373807907104, 0.38072913885116577, 0.0010416656732559204, 0.2049153596162796, 0.08191550523042679, 0.00041272197267971933, -0.09741029143333435, 0.15298031270503998, -0.15823930501937866, 0.2273726761341095, -0.026591433212161064, -0.047164350748062134, 0.03556134179234505, 0.04236111044883728, -0.08757233619689941, -0.15627893805503845, -0.33428817987442017, -0.04441550746560097, -0.6686053276062012, -0.002705441787838936, -0.39065393805503845, -0.1768663227558136, -0.08444733172655106, 0.16844256222248077, -0.11820022761821747, -0.10679976642131805, 0.10753218829631805, 0.09377893060445786, -0.015688294544816017, -0.04432870075106621, 0.7958477735519409, 0.1738208830356598, 0.024537036195397377, -0.12647569179534912, -0.01809895783662796, -0.27504339814186096, -0.17893880605697632, 0.4250867962837219, 0.32222604751586914, 0.09622395783662796, -0.08883101493120193, 0.11426503956317902, -0.0455729141831398, 0.04320746287703514, -0.031083622947335243, 0.014793112874031067, 0.033081959933042526, -0.03239293769001961, -0.3239293694496155, -0.2714943289756775, -0.3165075182914734, 0.06948783993721008, -0.01940104365348816, 0.07438421994447708, -0.10940393060445786, -0.24068287014961243, -0.31637731194496155, -0.04897008836269379, -0.31642070412635803, 0.059237558394670486, -0.024971064180135727, -0.26141494512557983, 0.016399014741182327, 0.08695022761821747, -0.22741608321666718, -0.0032986104488372803, 0.0876157358288765, 0.24010415375232697, 0.13702979683876038, -0.21010199189186096, 0.16752749681472778, 0.1896122694015503, -0.09354744851589203, 0.20631149411201477, -0.3081597089767456, 0.21452546119689941, 0.03572048619389534, 0.13376103341579437, 0.06669560074806213, 0.10632233321666718, 0.05581597238779068, -0.37332355976104736, 0.23043981194496155, 0.00783962570130825, -0.20630787312984467, -0.20598958432674408, -0.05797887593507767, 0.03072374127805233, 0.12352430075407028, 0.03938078507781029, -0.06480034440755844, 0.00850694440305233, -0.1841362863779068, 0.15108506381511688, 0.050289347767829895, -0.00786675326526165, -0.10971137136220932, 0.08709852397441864, -0.028964119032025337, 0.15199652314186096, 0.0016951949801295996, 0.05366753041744232, 0.0608723945915699, -0.4095097482204437, 0.22045716643333435, 0.00920139066874981, 0.1440972238779068, -0.186740443110466, -0.029029224067926407, 0.10495062917470932, 0.31088685989379883, -0.09103009104728699, 0.07821179926395416, -0.0660771057009697, 0.04623571038246155, -0.07454607635736465, 0.2316008359193802, 0.12181170284748077, -0.1926504671573639, -0.0804542824625969, 0.013946759514510632, -0.20170718431472778, 0.06495948880910873, -0.22146989405155182, 0.10870949178934097, 0.050614871084690094, -0.04007522761821747, -0.026967592537403107, 0.08153212070465088, 0.06006944179534912, -0.20353008806705475, 0.3525463044643402, -0.014434588141739368, -0.018807869404554367, 0.13707682490348816, -0.26299190521240234, 0.08423032611608505, -0.10124420374631882, -0.07586805522441864, 0.10075592994689941, -0.17337962985038757, -0.07908709347248077, -0.28096064925193787, -0.30460068583488464, 0.2535228729248047, 0.13071469962596893, -0.1284722238779068, 0.002003761474043131, 0.32402974367141724, -0.5594356656074524, -0.407016783952713, 0.00277777761220932, -0.34409719705581665, 0.0037145542446523905, -0.2800057828426361, -0.23765912652015686, 0.11843894422054291, -0.32364726066589355, 0.15230034291744232, -0.24168837070465088, 0.18906249105930328, -0.09861110895872116, -0.06744791567325592, -0.15491896867752075, 0.2862268388271332, 0.17073749005794525, -0.44045138359069824, -0.06362846493721008, -0.3818467855453491, 0.0401475690305233, -0.16576966643333435, 0.1501157432794571, 0.14570312201976776, 0.13331887125968933, -0.010597512125968933, 0.23338396847248077, -0.016377314925193787, -0.04233217611908913, 0.5549768209457397, 0.16282552480697632, 0.0032262729946523905, 0.20240160822868347, -0.2050745040178299, 0.1336672157049179, 0.01838107593357563, 0.07608868181705475, 0.11750578135251999, 0.25690826773643494, 0.01156684011220932, 0.10002170503139496, 0.15352647006511688, 0.5752893686294556, -0.0017216447740793228, -0.22501446306705475, 0.4052083194255829, -0.2446252852678299, -0.169460728764534, -0.0167100690305233, -0.11509331315755844, -0.31555989384651184, -0.2477719783782959, -0.10347222536802292, -0.13122105598449707, 0.1676359921693802, -0.21190319955348969, -0.22334344685077667, 0.2037181556224823, -0.08385416865348816, 0.14966723322868347, -0.7710069417953491, 0.11441695690155029, -0.05948621779680252, -0.0847339779138565, -0.11788193881511688, 0.02945602312684059, 0.1351453959941864, -0.22176648676395416, 0.19768518209457397, 0.3860532343387604, -0.12339409440755844, 0.20069444179534912, -0.44133391976356506, -0.15844906866550446, -0.884346067905426, -0.13835358619689941, -0.17047163844108582, -0.4504629373550415, 0.19036456942558289, 0.08345269411802292, 0.002633102238178253, -0.36530670523643494, 0.17102141678333282, -0.22907263040542603, -0.33676937222480774, -0.15390624105930328, 0.22207030653953552, -0.1928204596042633, -0.6195312738418579, -0.15930265188217163, 0.15154802799224854, -0.07352792471647263, -0.3233543038368225, 0.061678964644670486, -0.06381293386220932, -0.028544560074806213, 0.005664062220603228, -0.012485532090067863, 0.1577618569135666, 0.024580439552664757, 0.185756653547287, 0.3118344843387604, -0.049269385635852814, -0.18758681416511536, -0.1540020853281021, 0.2111310064792633, -0.3069797158241272, 0.1713324636220932, 0.13880208134651184, -0.5131365656852722, -0.24748262763023376, 0.24029405415058136, -0.021064814180135727, 0.02629665657877922, 0.0336371511220932, -0.047945600003004074, 0.44006800651550293, 0.07180627435445786, 0.505859375, -0.23563368618488312, 0.10628978163003922, -0.0012803822755813599, -0.4200159013271332, -0.03722511604428291, -0.18187934160232544, 0.25907841324806213, 0.027285879477858543, 0.12089119851589203, -0.23785807192325592, 0.17932580411434174, -0.32863134145736694, 0.11098813265562057, 0.1679723560810089, -0.08931567519903183, -0.1840277761220932, -0.1739601343870163, 0.17489872872829437, -0.25870949029922485, 0.2070891112089157, 0.11872106045484543, -0.027206307277083397, -0.5457754731178284, -0.0310329832136631, 0.18517795205116272, -0.22649919986724854, 0.1579861044883728, 0.017809607088565826, -0.12440682202577591, 0.11437355726957321, 0.2689236104488373, 0.14392361044883728, -0.032696761190891266, 0.17505787312984467, 0.21367910504341125, -0.09275896847248077, -0.05836588144302368, -0.40176504850387573, -0.0620659738779068, -0.03524305671453476, 0.11345485597848892, -0.12899304926395416, 0.0929398164153099, -0.3015914261341095, -0.03397713974118233, 0.47755712270736694, 0.12682291865348816, 0.030092593282461166, 0.22783926129341125, -0.045260053128004074, 0.0004629632458090782, 0.03521411865949631, 0.05551215633749962, -0.060662612318992615, 0.057342302054166794, 0.039633966982364655, 0.20915797352790833, -0.46155959367752075, 0.012037036940455437, 0.013642938807606697, 0.17322048544883728, 0.01089409738779068, -0.09328703582286835, 0.10046295821666718, -0.17543402314186096, 0.05477430298924446, 0.045927371829748154, 0.3130497634410858, 0.3643518388271332, -0.004853878170251846, 0.11649304628372192, -0.14445890486240387, 0.15674912929534912, -0.2093171328306198, 0.010825376026332378, -0.4081452488899231, -0.027879051864147186, -0.03760850429534912, 0.08564814925193787, 0.272685170173645, -0.008752893656492233, -0.12194734066724777, 0.3239004611968994, 0.11027199029922485, -0.20326966047286987, 0.12097800523042679, -0.06447482109069824, -0.03016492910683155, -0.18946759402751923, 0.11189959943294525, 0.07219328731298447, -0.08788339048624039, 0.39487844705581665, 0.006969762500375509, 0.2721281945705414, -0.20260529220104218, -0.034664351493120193, -0.27291667461395264, 0.1555410772562027, 0.04315682500600815, 0.015436921268701553, 0.017071761190891266, -0.16957464814186096, 0.14022713899612427, 0.27792245149612427, -0.037948496639728546, -0.05199652910232544, -0.34713539481163025, -0.12599825859069824, 0.24385127425193787, 0.11158131062984467, -0.10095486044883728, -0.27149882912635803, 0.17314814031124115, -0.3804325759410858, 0.014351852238178253, 0.3142939805984497, -0.056611690670251846, -0.1874421387910843, -0.15253183245658875, 0.24518229067325592, 0.0838179960846901, -0.28577837347984314, -0.0043165418319404125, 0.31279659271240234, -0.06759259104728699, 0.355902761220932, 0.16804108023643494, -0.2212456613779068, 0.2874276340007782, -0.09331957995891571, 0.1472945511341095, 0.06184782460331917, -0.0225694440305233, 0.27502891421318054, 0.11385995149612427, 0.047931134700775146, 0.16857638955116272, 0.16377313435077667, -0.049924496561288834, -0.1790400743484497, -0.021607348695397377, 0.06053964048624039, 0.18595196306705475, -0.06589987874031067, 0.10337094962596893, -0.22081886231899261, -0.4463541507720947, 0.1602141261100769, 0.29765623807907104, -0.19675925374031067, -0.007826967164874077, 0.04975224286317825, 0.12996238470077515, 0.27443575859069824, 0.1592881828546524, 0.2535807192325592, -0.1727190762758255, 0.0743308737874031, -0.1560329794883728, -0.233188658952713, 0.11093387752771378, 0.20655381679534912, 0.09270833432674408, -0.27972185611724854, 0.31707900762557983, 0.09682436287403107, -0.07463830709457397, 0.3690972328186035, 0.5248119235038757, -0.08307291567325592, -0.10628616809844971, -0.04224536940455437, -0.07938367873430252, 0.23292823135852814, -0.14379340410232544, 0.0510525144636631, -0.06875000149011612, 0.14665798842906952, -0.01228298619389534, 0.09308449178934097, 0.08614004403352737, 0.30128759145736694, 0.15531955659389496, 0.21065537631511688, -0.09291087836027145, -0.0883856862783432, 0.10005787014961243, -0.4086516201496124, 0.2537398636341095, -0.47110095620155334, -0.07401619851589203, -0.24367764592170715, -0.2033998668193817, -0.11841724067926407, 0.3356770873069763, -0.0028645824640989304, 0.1997988075017929, -0.046513307839632034, -0.061125580221414566, 0.13108746707439423, 0.031973376870155334, 0.6148726940155029, -0.0025896988809108734, 0.0073206014931201935, -0.06042390316724777, 0.14459995925426483, -0.146701380610466, -0.2888020873069763, -0.14722222089767456, -0.19403211772441864, -0.1669415384531021, -0.16929976642131805, 0.1094328761100769, -0.013660119846463203, -0.11964698880910873, -0.014673755504190922, 0.05525897070765495, -0.10782696306705475, -0.0783420130610466, -0.07717013359069824, -0.3411024212837219, 0.0007378477603197098, -0.2837384343147278, -0.1598307341337204, -0.129333034157753, -0.08770254254341125, 0.1456163227558136, -0.07386428862810135, -0.36471354961395264, 0.23946034908294678, 0.09403935074806213, -0.009071179665625095, -0.1279224455356598, 0.17462022602558136, 0.007436343468725681, 0.17148436605930328, 0.06150173395872116, -0.32056206464767456, 0.3474247455596924, 0.035105615854263306, 0.20007775723934174, 0.08527198433876038, -0.07982132583856583, 0.0907624363899231, -0.047120947390794754, 0.06279296427965164, 0.15541087090969086, 0.12800203263759613, 0.17928239703178406, 0.12669497728347778, 0.1730179488658905, -0.03638599440455437, 0.17300347983837128, 0.07852828502655029, -0.255092591047287, 0.10323350131511688, 0.17701099812984467, -0.0206163190305233, 0.11600838601589203, -0.1139322891831398, -0.3912760615348816, -0.009639033116400242, -0.10647424310445786, -0.20299841463565826, 0.15312771499156952, 0.25316840410232544, -0.04278067126870155, 0.06143934279680252, 0.21198639273643494, 0.1646556705236435, 0.028330257162451744, -0.10744357109069824, 0.013888887129724026, 0.0923394039273262, -0.36407697200775146, 0.3182002305984497, 0.03753616660833359, -0.016903571784496307, 0.22578123211860657, 0.03182870149612427, 0.07105034589767456, -0.18444834649562836, 0.15876735746860504, 0.08223380148410797, 0.3818865418434143, -0.05460069328546524, -0.08877314627170563, -0.07391493022441864, -0.06297742575407028, 0.14256365597248077, 0.11021412163972855, -0.10836227238178253, 0.45151183009147644, 0.15065103769302368, 0.02805989608168602, 0.3222222328186035, 0.07905092090368271, 0.3711045980453491, -0.3402343690395355, 0.01282552070915699, 0.049008969217538834, -0.05101996660232544, 0.07439959049224854, 0.2940031588077545, 0.09774304926395416, 0.37664929032325745, -0.02899305522441864, -0.015784144401550293, -0.19523563981056213, -0.28165507316589355, 0.061953846365213394, -0.1783275306224823, -0.0748697891831398, -0.1450231522321701, -0.03391203656792641, -0.20707464218139648, 0.19931097328662872, -0.43859952688217163, -0.2295970767736435]\n"
     ]
    }
   ],
   "source": [
    "# validate that node has an embedding associated with it\n",
    "for idx, node in enumerate(nodes):\n",
    "    if node.id_ == \"node_0\":\n",
    "        print(node.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2620ecd1-c357-49a0-8921-7de63903f870",
   "metadata": {},
   "source": [
    "## Create the VectorIndex \n",
    "This creates our vector database, in memory in this case,  using the nodes that were created in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25602778-44d3-4adf-b3e2-68b679feeea2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_index = VectorStoreIndex(nodes=nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb1160-b3e8-445d-8680-fa9d46faea06",
   "metadata": {},
   "source": [
    "## Test that we have a valid starting point for our evaluation\n",
    "We run a quick system test with the defaul llama_index RAG workflow with a question that is relevant to our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3006bf-14de-4c74-93dd-3a584bcb5be9",
   "metadata": {},
   "source": [
    "Instantiate a query engine object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7e3b4be-5fe1-4789-b7b9-bf17cb6a9f77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c163ad-7a8c-40e1-a9f4-8caac25e8dc1",
   "metadata": {},
   "source": [
    "Specify a question that has can be answered by the document(s) that have been ingested. For the default document, the following is a valid question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a3a8e95-22ae-45e2-9f9b-d0734d6a4bea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_query=\"What did the author do growing up?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1479cecf-4725-45f6-be71-7cd5bf4cf915",
   "metadata": {},
   "source": [
    "Run the default RAG pipeline with the example query. This should give a meaningful result. Don't worry if the answer is overly verbose, etc. We'll fix that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0a8af86-4544-4286-be1a-a32b7fe55c66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The author attended RISD (Rhode Island School of Design) and learned to paint there. Prior to that, he was not one of the kids who could draw in high school. He dropped out of RISD in 1993 and moved to New York City to pursue a career as a painter. He had a friend, Idelle Weber, who was a painter and taught him a lot. He was also nervous about money and decided to write another book on Lisp to live off the royalties and paint. He also worked on various projects such as spam filters, cooking for groups, and buying a building in Cambridge to use as an office. He eventually met his future partner, Jessica Livingston, at a party and they started a venture capital firm together.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(example_query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c06687f-c443-4bdb-8e70-25686fbd3564",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6127b15d-cb49-43ab-8f8e-a908915eb6c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluate the retrieval accuracy of the VectorIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85730c7c-81f2-493c-8fe0-3a59204e2b7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create a set of question and node (context) pairs to drive the tests that follow\n",
    "This uses the llm that give the methods and the document data stored in the nodes (created during document ingestion)\n",
    "\n",
    "This will make many calls to the specified LLM (num_questions_per_chunk * number of nodes). This will likely be throttled by Bedrock. The llama_index API will work through the throttling except in extreme cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3a0e486-180b-42e3-8ca3-852e73690c90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3/44 [00:09<02:19,  3.41s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      "Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      "  9%|▉         | 4/44 [00:31<07:03, 10.58s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 11%|█▏        | 5/44 [00:47<08:12, 12.63s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 14%|█▎        | 6/44 [01:05<09:06, 14.38s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 16%|█▌        | 7/44 [01:24<09:51, 15.99s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 18%|█▊        | 8/44 [01:42<09:58, 16.63s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 20%|██        | 9/44 [01:59<09:51, 16.89s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 23%|██▎       | 10/44 [02:21<10:21, 18.29s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 27%|██▋       | 12/44 [02:54<09:06, 17.07s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 30%|██▉       | 13/44 [03:15<09:31, 18.44s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 32%|███▏      | 14/44 [03:32<09:02, 18.07s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 34%|███▍      | 15/44 [03:51<08:52, 18.37s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      "Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 36%|███▋      | 16/44 [04:10<08:34, 18.36s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 39%|███▊      | 17/44 [04:30<08:30, 18.92s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 41%|████      | 18/44 [04:48<08:06, 18.70s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 43%|████▎     | 19/44 [05:09<08:01, 19.24s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 45%|████▌     | 20/44 [05:26<07:24, 18.51s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 48%|████▊     | 21/44 [05:47<07:26, 19.39s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 50%|█████     | 22/44 [06:04<06:50, 18.66s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 52%|█████▏    | 23/44 [06:22<06:26, 18.41s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 55%|█████▍    | 24/44 [06:39<06:03, 18.19s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      "Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 57%|█████▋    | 25/44 [07:00<05:57, 18.84s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 59%|█████▉    | 26/44 [07:19<05:41, 19.00s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 61%|██████▏   | 27/44 [07:41<05:39, 19.94s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 64%|██████▎   | 28/44 [07:57<04:58, 18.68s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 66%|██████▌   | 29/44 [08:17<04:43, 18.92s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 68%|██████▊   | 30/44 [08:33<04:13, 18.09s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 70%|███████   | 31/44 [08:52<03:58, 18.32s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 73%|███████▎  | 32/44 [09:11<03:42, 18.53s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 75%|███████▌  | 33/44 [09:30<03:27, 18.90s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 77%|███████▋  | 34/44 [09:48<03:05, 18.58s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 80%|███████▉  | 35/44 [10:04<02:39, 17.73s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      "Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 82%|████████▏ | 36/44 [10:24<02:26, 18.34s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 84%|████████▍ | 37/44 [10:40<02:03, 17.63s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 86%|████████▋ | 38/44 [10:58<01:46, 17.81s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 89%|████████▊ | 39/44 [11:18<01:32, 18.55s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      "Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 91%|█████████ | 40/44 [11:40<01:18, 19.68s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 93%|█████████▎| 41/44 [11:59<00:57, 19.33s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 95%|█████████▌| 42/44 [12:19<00:39, 19.68s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      " 98%|█████████▊| 43/44 [12:37<00:19, 19.13s/it]Retrying llama_index.llms.bedrock.utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again..\n",
      "100%|██████████| 44/44 [12:54<00:00, 17.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 989 ms, sys: 52.6 ms, total: 1.04 s\n",
      "Wall time: 12min 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "qa_dataset = generate_question_context_pairs(nodes, num_questions_per_chunk=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c9794d-4890-42ca-867b-5558955932e9",
   "metadata": {},
   "source": [
    "Take a look at the sample queries generated. This should show a meaningful questions related to your document content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d29a7fc-22b4-4ff4-98d6-764280755a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What programming language did the author use when he first started programming on the IBM 1401 computer in 9th grade?\n",
      "In what year did the narrator first start programming on a microcomputer, and what type of computer was it?\n",
      "In what novel did the author describe an intelligent computer named Mike that inspired the speaker to pursue a career in AI?\n",
      "In which universities did the author apply for graduate school in Artificial Intelligence during the 1980s?\n",
      "In what year did Paul Graham write most of his book \"On Lisp\"?\n",
      "In what year did the author first consider the idea of becoming an artist after visiting the Carnegie Institute?\n",
      "What topic did the author choose for his PhD dissertation in computer science, despite not having a significant amount of time to write it?\n",
      "What art school did the author initially apply to and why?\n",
      "What arrangement existed between the students and faculty in the painting department at the Accademia, allowing both parties to adhere to the conventions of a 19th century atelier without teaching or learning anything new?\n",
      "Based on the author's experience, what is one advantage of painting still lifes compared to painting people?\n",
      "What inspired Interleaf to add a scripting language to their software, and what language did they choose for it?\n",
      "What was the author's daily budget for expenses in Florence, and how did his income from Interleaf exceed this amount?\n",
      "What is the relationship between art school and the art world, according to the author's experience at RISD?\n",
      "In what year did the author drop out of RISD and move to New York City to pursue a career in painting?\n",
      "Who was Idelle Weber and what was she known for in the art world?\n",
      "In what year did Paul Graham and Robert Morris start working on creating software for building gallery websites and online stores?\n",
      "When did the team first create a functional web app version of their store builder?\n",
      "Who were the two programmers recruited by the speaker to help build the WYSIWYG site builder, and what were their unique qualities?\n",
      "What year did the company open for business with six stores?\n",
      "What was the unconventional approach taken by the startup to acquire users in the early stages, and how did it benefit them in the long run?\n",
      "Based on the context, why did the speaker feel relieved when Yahoo bought Viaweb in the summer of 1998?\n",
      "What was the reason why the author felt the year between 1998 and 1999 was the least productive of his life?\n",
      "In what state did the author initially attempt to start his painting career after leaving Yahoo?\n",
      "In what way did the artist create a second still life painting using the first one as an underpainting?\n",
      "What was the initial name for the type of company Paul Graham and his team were creating, which later became known as \"software as a service\"?\n",
      "In what year did Paul Graham first realize the potential of the web as a platform for publishing essays and reaching a large audience?\n",
      "In what context did the author first begin publishing essays and why did he find it encouraging despite it being a marginal medium at the time?\n",
      "Who were the three separate hosts for the big party at the author's house in October 2003?\n",
      "What were the reasons given in the text for why the speaker believed venture capital firms should make a larger number of smaller investments instead of a few large ones?\n",
      "What was the background and motivation behind the founding of Y Combinator in 2005?\n",
      "What led Paul Graham and his team to come up with the idea for the Summer Founders Program (SFP)?\n",
      "Who were some of the notable individuals who were part of the first batch of the Summer Founders Program, and what companies did they go on to found?\n",
      "What role did the Y Combinator community play in the growth and success of the startups in the program?\n",
      "What was the comparison made between dealing with problems at YC and running a marathon with a blister?\n",
      "Who offered unsolicited advice to the author during his time at Viaweb, and under what circumstances?\n",
      "Who did the speaker initially approach to take over as president of Y Combinator in 2013?\n",
      "What led the author to stop painting in November 2014, and why did he find it a chore to finish the painting he was working on at that time?\n",
      "In what year did McCarthy's graduate student Steve Russell suggest using Lisp as a programming language for computers?\n",
      "In what country did the author and his family move to in the summer of 2016, and why did they make this decision?\n",
      "In which country did the author and his family move to live for an extended period of time, and why did they make this decision?\n",
      "In what historical Italian city did the author describe walking through various landmarks, including the Pitti Palace, Orsanmichele, the Duomo, and the Baptistery?\n",
      "What was the initial name of Y Combinator before it was renamed, and why was the change made?\n",
      "What was the original name of Y Combinator before it was renamed, and why was the name changed?\n",
      "Based on the context, what is the author's perspective on the difference between invented and discovered concepts, using the example of space aliens and Lisp programming language?\n"
     ]
    }
   ],
   "source": [
    "for item in list(qa_dataset.queries.items()):\n",
    "    print(item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d10a4af-f49d-4eea-82ca-e7d5cca9b990",
   "metadata": {},
   "source": [
    "## Instantiate a retriever against the index for testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735fad7c-f10c-46a3-8a9a-6d3e5c25b64d",
   "metadata": {},
   "source": [
    "### Set the number of items to return from the Retriever\n",
    "This is a trade-off item, more returned content is not always better. Consider how this may impact your pipeline and evaluation results and experiment with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d66407c-ea89-4c90-8be0-1bc70c2700fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KEY CELL: 03\n",
    "\n",
    "number_of_items_to_return = 2\n",
    "# number_of_items_to_return = 3\n",
    "# number_of_items_to_return = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d6db691-6af4-4856-8ad2-604c0c6f629c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = vector_index.as_retriever(similarity_top_k=number_of_items_to_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ab82df-ebaa-4a2f-a98b-298198672f26",
   "metadata": {},
   "source": [
    "Run a quick system test on the retriever and check that the output nodes look reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3edf0400-0e17-4d7f-aee7-95546b8eaa4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_query=\"What did the author do growing up?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5e6327e-46ca-4e1d-9979-11c86471d784",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NodeWithScore(node=TextNode(id_='node_13', embedding=None, metadata={'file_path': '/home/ec2-user/SageMaker/elvtr-ai-solution-architect/class-11/source_docs/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2025-02-19', 'last_modified_date': '2025-02-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='5a4e7269-3f03-41dd-aebd-1b8e8d7a5fea', node_type='4', metadata={'file_path': '/home/ec2-user/SageMaker/elvtr-ai-solution-architect/class-11/source_docs/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2025-02-19', 'last_modified_date': '2025-02-19'}, hash='0c3c3f46cac874b495d944dfc4b920f6b68817dbbb1699ecc955d1fafb2bf87b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3ef8b653-8cc6-4857-bd14-c9d667db463a', node_type='1', metadata={'file_path': '/home/ec2-user/SageMaker/elvtr-ai-solution-architect/class-11/source_docs/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2025-02-19', 'last_modified_date': '2025-02-19'}, hash='b1fc475d83d86992a59d05324bb7f79b0d80ed0d926e56d234a65f2031685cb6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ae8f7e61-f208-439a-bb88-4ed9b0c0ffb7', node_type='1', metadata={}, hash='e6e60106ef881b7f15f522127c5ae64f0ce63f4405aefd4eb5019ef5baf6f922')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"they kept going, because painting was what they did. I was not one of the kids who could draw in high school, but at RISD I was definitely closer to their tribe than the tribe of signature style seekers.\\n\\nI learned a lot in the color class I took at RISD, but otherwise I was basically teaching myself to paint, and I could do that for free. So in 1993 I dropped out. I hung around Providence for a bit, and then my college friend Nancy Parmet did me a big favor. A rent-controlled apartment in a building her mother owned in New York was becoming vacant. Did I want it? It wasn't much more than my current place, and New York was supposed to be where the artists were. So yes, I wanted it! [7]\\n\\nAsterix comics begin by zooming in on a tiny corner of Roman Gaul that turns out not to be controlled by the Romans. You can do something similar on a map of New York City: if you zoom in on the Upper East Side, there's a tiny corner that's not rich, or at least wasn't in 1993. It's called Yorkville, and that was my new home. Now I was a New York artist — in the strictly technical sense of making paintings and living in New York.\\n\\nI was nervous about money, because I could sense that Interleaf was on the way down. Freelance Lisp hacking work was very rare, and I didn't want to have to program in another language, which in those days would have meant C++ if I was lucky. So with my unerring nose for financial opportunity, I decided to write another book on Lisp. This would be a popular book, the sort of book that could be used as a textbook. I imagined myself living frugally off the royalties and spending all my time painting. (The painting on the cover of this book, ANSI Common Lisp, is one that I painted around this time.)\\n\\nThe best thing about New York for me was the presence of Idelle and Julian Weber. Idelle Weber was a painter, one of the early photorealists, and I'd taken her painting class at Harvard. I've never known a teacher more beloved by her students. Large numbers of former students kept in touch with her, including me. After I moved to New York\", mimetype='text/plain', start_char_idx=22263, end_char_idx=24339, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.33514721355914584), NodeWithScore(node=TextNode(id_='node_27', embedding=None, metadata={'file_path': '/home/ec2-user/SageMaker/elvtr-ai-solution-architect/class-11/source_docs/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2025-02-19', 'last_modified_date': '2025-02-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='5a4e7269-3f03-41dd-aebd-1b8e8d7a5fea', node_type='4', metadata={'file_path': '/home/ec2-user/SageMaker/elvtr-ai-solution-architect/class-11/source_docs/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2025-02-19', 'last_modified_date': '2025-02-19'}, hash='0c3c3f46cac874b495d944dfc4b920f6b68817dbbb1699ecc955d1fafb2bf87b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3e6e84ff-b697-41a2-b29c-f39bdab83081', node_type='1', metadata={'file_path': '/home/ec2-user/SageMaker/elvtr-ai-solution-architect/class-11/source_docs/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2025-02-19', 'last_modified_date': '2025-02-19'}, hash='8400ddde623c1bf98d8eee6c8a338d304bcdfbe812d543967b57bbeacc0bab95'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3d67a5bf-9ca2-4ae5-bc23-126ace6f2e3d', node_type='1', metadata={}, hash='fae6b37cd435ea0405e636a718778829fabaf258696a734ef77370a0a36c07ac')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"motives are a big danger for the ambitious. If anything is going to lead you astray, it will be the desire to impress people. So while working on things that aren't prestigious doesn't guarantee you're on the right track, it at least guarantees you're not on the most common type of wrong one.\\n\\nOver the next several years I wrote lots of essays about all kinds of different topics. O'Reilly reprinted a collection of them as a book, called Hackers & Painters after one of the essays in it. I also worked on spam filters, and did some more painting. I used to have dinners for a group of friends every thursday night, which taught me how to cook for groups. And I bought another building in Cambridge, a former candy factory (and later, twas said, porn studio), to use as an office.\\n\\nOne night in October 2003 there was a big party at my house. It was a clever idea of my friend Maria Daniels, who was one of the thursday diners. Three separate hosts would all invite their friends to one party. So for every guest, two thirds of the other guests would be people they didn't know but would probably like. One of the guests was someone I didn't know but would turn out to like a lot: a woman called Jessica Livingston. A couple days later I asked her out.\\n\\nJessica was in charge of marketing at a Boston investment bank. This bank thought it understood startups, but over the next year, as she met friends of mine from the startup world, she was surprised how different reality was. And how colorful their stories were. So she decided to compile a book of interviews with startup founders.\\n\\nWhen the bank had financial problems and she had to fire half her staff, she started looking for a new job. In early 2005 she interviewed for a marketing job at a Boston VC firm. It took them weeks to make up their minds, and during this time I started telling her about all the things that needed to be fixed about venture capital. They should make a larger number of smaller investments instead of a handful of giant ones, they should be funding younger, more technical founders instead of MBAs, they should let the founders remain as CEO, and so on.\\n\\nOne of my tricks for writing essays had always been to give talks. The prospect of having\", mimetype='text/plain', start_char_idx=45940, end_char_idx=48173, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.32580847581174915)]\n"
     ]
    }
   ],
   "source": [
    "retrieved_nodes = retriever.retrieve(example_query)\n",
    "print(retrieved_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7f47e2-1e69-4a8e-a26c-886ef2e4dd3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate the Quality of Retrieval from the VectorIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5768664c-f6da-4870-a882-1affb219a2d1",
   "metadata": {},
   "source": [
    "Instantiate a RetrieverEvaluator with the metrics that we want to review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99063386-621d-4ee7-93e6-17ab95e49839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = [\"hit_rate\", \"mrr\", \"precision\", \"recall\"]\n",
    "\n",
    "retriever_evaluator = RetrieverEvaluator.from_metric_names(metrics, retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26ffc053-eab3-42f8-8b21-d8abcc5e19e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: In what year did the narrator first start programming on a microcomputer, and what type of computer was it?\n",
      "Metrics: {'hit_rate': 1.0, 'mrr': 1.0, 'precision': 0.5, 'recall': 1.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on a single query\n",
    "# The output is verbose, but may be useful for looking at specific results\n",
    "\n",
    "query_id = 1  # change this to math the query id of interest\n",
    "\n",
    "sample_id, sample_query = list(qa_dataset.queries.items())[query_id]\n",
    "sample_expected = qa_dataset.relevant_docs[sample_id]\n",
    "\n",
    "eval_result = retriever_evaluator.evaluate(sample_query, sample_expected)\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abf98b03-9305-46f3-a9fe-52cbd1d1cd97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetrievalEvalResult(query='In what year did the narrator first start programming on a microcomputer, and what type of computer was it?', expected_ids=['node_1'], expected_texts=None, retrieved_ids=['node_1', 'node_0'], retrieved_texts=[\"memory is of the moment I learned it was possible for programs not to terminate, when one of mine didn't. On a machine without time-sharing, this was a social as well as a technical error, as the data center manager's expression made clear.\\n\\nWith microcomputers, everything changed. Now you could have a computer sitting right in front of you, on a desk, that could respond to your keystrokes as it was running instead of just churning through a stack of punch cards and then stopping. [1]\\n\\nThe first of my friends to get a microcomputer built it himself. It was sold as a kit by Heathkit. I remember vividly how impressed and envious I felt watching him sitting in front of it, typing programs right into the computer.\\n\\nComputers were expensive in those days and it took me years of nagging before I convinced my father to buy one, a TRS-80, in about 1980. The gold standard then was the Apple II, but a TRS-80 was good enough. This was when I really started programming. I wrote simple games, a program to predict how high my model rockets would fly, and a word processor that my father used to write at least one book. There was only room in memory for about 2 pages of text, so he'd write 2 pages at a time and then print them out, but it was a lot better than a typewriter.\\n\\nThough I liked programming, I didn't plan to study it in college. In college I was going to study philosophy, which sounded much more powerful. It seemed, to my naive high school self, to be the study of the ultimate truths, compared to which the things studied in other fields would be mere domain knowledge. What I discovered when I got to college was that the other fields took up so much of the space of ideas that there wasn't much left for these supposed ultimate truths. All that seemed left for philosophy were edge cases that people in other fields felt could safely be ignored.\\n\\nI couldn't have put this into words when I was 18. All I knew at the time was that I kept taking philosophy courses and they kept being boring. So I decided to switch to AI.\\n\\nAI was in the air in the mid 1980s, but there were two things especially that made me want to work on\", 'What I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn\\'t write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\\n\\nThe first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district\\'s 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was like a mini Bond villain\\'s lair down there, with all these alien-looking machines — CPU, disk drives, printer, card reader — sitting up on a raised floor under bright fluorescent lights.\\n\\nThe language we used was an early version of Fortran. You had to type programs on punch cards, then stack them in the card reader and press a button to load the program into memory and run it. The result would ordinarily be to print something on the spectacularly loud printer.\\n\\nI was puzzled by the 1401. I couldn\\'t figure out what to do with it. And in retrospect there\\'s not much I could have done with it. The only form of input to programs was data stored on punched cards, and I didn\\'t have any data stored on punched cards. The only other option was to do things that didn\\'t rely on any input, like calculate approximations of pi, but I didn\\'t know enough math to do anything interesting of that type. So I\\'m not surprised I can\\'t remember any programs I wrote, because they can\\'t have done much. My clearest memory is of the moment I learned it was possible for programs not to terminate, when one of mine didn\\'t. On a machine without time-sharing, this was a social as well as a technical error, as the data center manager\\'s expression made clear.\\n\\nWith microcomputers, everything changed. Now you could have a computer sitting right in front of you, on a desk, that could respond to your keystrokes as it was running instead of just churning through a stack of punch cards and'], mode=<RetrievalEvalMode.TEXT: 'text'>, metric_dict={'hit_rate': RetrievalMetricResult(score=1.0, metadata={}), 'mrr': RetrievalMetricResult(score=1.0, metadata={}), 'precision': RetrievalMetricResult(score=0.5, metadata={}), 'recall': RetrievalMetricResult(score=1.0, metadata={})})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to see detail on which nodes were returned, etc, we can look at the whole returned object\n",
    "eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e410697-2972-4b9f-8f8d-94d477afdc32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Run evaluation on the entire test dataset (autogenerated above)\n",
    "eval_results = await retriever_evaluator.aevaluate_dataset(qa_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20614f76-9896-4253-8a5e-e101a1f082ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_results(name, eval_results):\n",
    "    metric_dicts = []\n",
    "    for eval_result in eval_results:\n",
    "        metric_dict = eval_result.metric_vals_dict\n",
    "        metric_dicts.append(metric_dict)\n",
    "\n",
    "    full_df = pd.DataFrame(metric_dicts)\n",
    "    hit_rate = full_df[\"hit_rate\"].mean()\n",
    "    mrr = full_df[\"mrr\"].mean()\n",
    "    precision = full_df[\"precision\"].mean()\n",
    "    recall = full_df[\"recall\"].mean()\n",
    "\n",
    "    metric_df = pd.DataFrame({\"retrievers\": [name],\n",
    "                              \"hit_rate\": [hit_rate], \"mrr\": [mrr],\n",
    "                              \"precision\": [precision], \"recall\": [recall],\n",
    "                             })\n",
    "    return metric_df, full_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1159cf-271e-46b2-8264-4bd89b39b648",
   "metadata": {},
   "source": [
    "### Top-level Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42016d73-4f1a-4d09-adc0-5bd8a8ffda85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>top-2 eval</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.534091</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   retrievers  hit_rate       mrr  precision    recall\n",
       "0  top-2 eval  0.636364  0.534091   0.318182  0.636364"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary, detail = display_results(f\"top-{number_of_items_to_return} eval\", eval_results)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85ec8877-bec8-4c50-b2f0-67ad6b7b5dab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hit_rate  mrr  precision  recall\n",
       "0        0.0  0.0        0.0     0.0\n",
       "1        1.0  1.0        0.5     1.0\n",
       "2        0.0  0.0        0.0     0.0\n",
       "3        1.0  1.0        0.5     1.0\n",
       "4        0.0  0.0        0.0     0.0\n",
       "5        0.0  0.0        0.0     0.0\n",
       "6        1.0  1.0        0.5     1.0\n",
       "7        1.0  0.5        0.5     1.0\n",
       "8        0.0  0.0        0.0     0.0\n",
       "9        1.0  1.0        0.5     1.0\n",
       "10       0.0  0.0        0.0     0.0\n",
       "11       1.0  1.0        0.5     1.0\n",
       "12       1.0  1.0        0.5     1.0\n",
       "13       1.0  0.5        0.5     1.0\n",
       "14       0.0  0.0        0.0     0.0\n",
       "15       1.0  0.5        0.5     1.0\n",
       "16       0.0  0.0        0.0     0.0\n",
       "17       1.0  0.5        0.5     1.0\n",
       "18       0.0  0.0        0.0     0.0\n",
       "19       1.0  1.0        0.5     1.0\n",
       "20       1.0  1.0        0.5     1.0\n",
       "21       1.0  1.0        0.5     1.0\n",
       "22       1.0  1.0        0.5     1.0\n",
       "23       0.0  0.0        0.0     0.0\n",
       "24       1.0  1.0        0.5     1.0\n",
       "25       1.0  1.0        0.5     1.0\n",
       "26       1.0  1.0        0.5     1.0\n",
       "27       1.0  0.5        0.5     1.0\n",
       "28       1.0  1.0        0.5     1.0\n",
       "29       1.0  1.0        0.5     1.0\n",
       "30       1.0  0.5        0.5     1.0\n",
       "31       1.0  1.0        0.5     1.0\n",
       "32       0.0  0.0        0.0     0.0\n",
       "33       0.0  0.0        0.0     0.0\n",
       "34       0.0  0.0        0.0     0.0\n",
       "35       1.0  0.5        0.5     1.0\n",
       "36       0.0  0.0        0.0     0.0\n",
       "37       1.0  0.5        0.5     1.0\n",
       "38       0.0  0.0        0.0     0.0\n",
       "39       1.0  1.0        0.5     1.0\n",
       "40       1.0  0.5        0.5     1.0\n",
       "41       1.0  1.0        0.5     1.0\n",
       "42       0.0  0.0        0.0     0.0\n",
       "43       1.0  1.0        0.5     1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optionally, look at the detailed, question by question metrics:\n",
    "detail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24d393f-7b77-4de0-86a1-569fb4d6de5c",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1f08a3-317c-46fc-8ccb-3f0b133897aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Assignment Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753fbf95-39a4-43e4-b1ce-8296f28c8737",
   "metadata": {},
   "source": [
    "**01** Run the notebook in full, with the default, provided, document set (one document in .txt file).\n",
    "\n",
    "Copy the Top-level Evaluation Results (from the cell a little way above this one) into this cell.\n",
    "\n",
    "Save the notebook and rename is as `capstone-02-01-first-run.ipynb`. Download the notebook for assignment submission.\n",
    "\n",
    "**Answer**\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|--------|\n",
    "| Retriever Hit Rate | 0.636364 |\n",
    "| MRR | 0.534091 |\n",
    "| Precision | 0.318182 |\n",
    "| Recall | 0.636364 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a91685-af8e-40c3-9d75-8e427a227043",
   "metadata": {},
   "source": [
    "**02** Replace the default document with one of more of your own documents and re-run all the cells.\n",
    "\n",
    "- First make a copy of the first notebook and paste it into the same directory.\n",
    "- Delete the original content on source_docs\n",
    "- Delete the cell in the notebook that will download the original content again to source_docs\n",
    "- Upload your content to source_docs\n",
    "- Initially test with a small set - 20 to 40 nodes aka document chunks - to save you time as you experiment. This may mean that you delete some of your content, to reduce its size. \n",
    "- Run the whole notebook with your small set of  test documents and observe the results.\n",
    "\n",
    "Wrapping up:\n",
    "- Copy the Top-level Evaluation Results (from the cell a little way above this one) into this cell.\n",
    "- The top-level results returned are your `baseline` results. As you experiment with different configurations, in the following assignment tasks, you will see the route to improved accuracy from this baseline.\n",
    "- Describe your test dataset in this cell. How many documents, how many chunks, what is the topic of the content, what is the lanuage.\n",
    "\n",
    "This completes this step.\n",
    "\n",
    "- Save and rename the notebook as `capstone-02-02-my-data-baseline.ipynb`. Download the notebook for assignment submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffc93a6-9787-4fe3-aa06-15d06fb3b668",
   "metadata": {},
   "source": [
    "**03** Using your data experiment with different embedding models\n",
    "\n",
    "- First make a copy of the previous notebook,`capstone-02-02-my-data-baseline.ipynb`, and paste it into the same directory.\n",
    "- Change which embedding model is going to be used from the original setting. \n",
    "There are three other options prepared in this notebook, see `KEY CELL 01`. \n",
    "- Run all the following cells in the notebook and note the in accuracy metrics for the selected model.\n",
    "- Repeat with one or more of the embeddings models, noting the accuracy metrics for the selected model, each time.\n",
    "Note: Changing the embeddings model will change the accuracy of the retriever. Exactly how much will depend on your content.\n",
    "\n",
    "Wrapping up:\n",
    "- For each embeddings model that you experiment with, copy the Top-level Evaluation Results (from the cell a little way above this one) into this cell, along with an indication as to which embeddings model was being used.\n",
    "\n",
    "- Briefly describe your results in this cell. Which model was best, did you see a major improvement in the metrics, can you suggest a reason for why the best embeddings model is performing better than the worst.\n",
    "\n",
    "This completes this step.\n",
    "\n",
    "\n",
    "- Save and rename the notebook as `capstone-02-03-my-data-embeddings.ipynb`. Download the notebook for assignment submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10b739f-5af8-4719-8d69-ae70af9ed9c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "**04** Using your data experiment with different ingestion pipelines\n",
    "\n",
    "- First make a copy of the previous notebook,`capstone-02-03-my-data-embeddings.ipynb`, and paste it into the same directory.\n",
    "- Make sure the the notebook is configured to use the best performing embeddings model.\n",
    "- Change which pipeline is going to be used from the original setting. \n",
    "There is one other options prepared in this notebook, see `KEY CELL 02`.\n",
    "- Run all the following cells in the notebook and note the in accuracy metrics for the selected pipeline.\n",
    "- Optionally, create your own pipeline and experiment with that to further improve the  accuracy metrics of your solution.\n",
    "Note: Changing the ingestion should change the accuracy of the retriever. Exactly how much will depend on your content. \n",
    "The two example pipelines in this notebook may not make much of a difference for your content. \n",
    "If you have time, you will learn most by experimenting with creating you own and seeing the change in the metrics.\n",
    "\n",
    "Wrapping up:\n",
    "- For each pipeline that you experiment with, copy the Top-level Evaluation Results (from the cell a little way above this one) into this cell, along with the definition of the pipeline being used.\n",
    "\n",
    "- Briefly describe your results in this cell. Which pipeline was best, did you see a major improvement in the metrics, can you suggest a reason for why the best pipeline is performing better than the worst.\n",
    "\n",
    "This completes this step.\n",
    "\n",
    "\n",
    "- Save and rename the notebook as `capstone-02-04-my-data-pipeline.ipynb`. Download the notebook for assignment submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99fec15-e26a-4764-ba7e-db8e50d43d81",
   "metadata": {
    "tags": []
   },
   "source": [
    "**05** Using your data experiment with different values of k\n",
    "\n",
    "- First make a copy of the previous notebook,`capstone-02-04-my-data-pipeline.ipynb`, and paste it into the same directory.\n",
    "- Make sure the the notebook is configured to use the best performing pipeline and embeddings model.\n",
    "- Change the value of *k* that is going to be used from the original setting. \n",
    "There are two other options prepared in this notebook, see `KEY CELL 03`.\n",
    "- Run all the cells that follow below in the notebook and note the in accuracy metrics for the selected value of *k*. \n",
    "*Note*: with this setting, you do not need to re-run the cells above the cell where you make the update.\n",
    "\n",
    "\n",
    "Wrapping up:\n",
    "- For each value of *k* set for the `retriever`, run the evaluation and copy the Top-level Evaluation Results into this cell, along with noting the value of *k* being used.\n",
    "\n",
    "- Briefly describe your results in this cell. Which value of *k* gave the best results, did you see a major improvement in the metrics, can you suggest a reason for why the best pipeline is performing better than the worst.\n",
    "\n",
    "This completes this step.\n",
    "\n",
    "\n",
    "- Save and rename the notebook as `capstone-02-05-my-data-pipeline-with-k.ipynb`. Download the notebook for assignment submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a9be75-ae92-480b-b769-0432f1e2c87e",
   "metadata": {},
   "source": [
    "**06** Summarize\n",
    "\n",
    "- Breifly summarize, in four paragraphs what your learned, regarding the following topics:\n",
    "    - The configuration of the retriever for your content\n",
    "    - The process of experimentating with different settings and evaluating the results\n",
    "    - Which evaluation metric was most useful and why\n",
    "    - What might you do next, if you had a 40 hours or more to work on this, to further improve the quality of the retriever\n",
    "- Save your summary in this cell.\n",
    "    \n",
    "This completes this step.\n",
    "\n",
    "\n",
    "- Save and rename the notebook as `capstone-02-06-summary.ipynb`. Download the notebook for assignment submission.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e6ea1c",
   "metadata": {},
   "source": [
    "Post each of the notebooks, individually, to submit your assignment. Do not zip the set of notebooks, as that makes it harder for the grading process. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ace4c60",
   "metadata": {},
   "source": [
    "## The following assignment tasks are completely optional \n",
    "The follow tasks are intended for students who want to dive deeper. They are more open ended and require changing and augmenting the code share above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd8a7f5",
   "metadata": {},
   "source": [
    "**Optional Task 1** Text Chunking\n",
    "\n",
    "Experiment further with advanced chunking options and see if you can further improve the accuracy of the your Retriever (by having the better pre-processed data).\n",
    "\n",
    "Good candidates to look are [Semantic chunking](https://docs.llamaindex.ai/en/stable/examples/node_parsers/semantic_chunking/), and\n",
    "[Semantic double merging chunking](https://docs.llamaindex.ai/en/stable/examples/node_parsers/semantic_double_merging_chunking/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb2610f",
   "metadata": {},
   "source": [
    "**Optional Task 2** Explore other Transformations\n",
    "\n",
    "Using the following [document](https://docs.llamaindex.ai/en/stable/module_guides/loading/ingestion_pipeline/transformations/) as your starting point, consider which transformations would be most applicable to your set of documents and experiment and see the impact of those changes.\n",
    "\n",
    "There are lots of [transformations](https://docs.llamaindex.ai/en/v0.9.48/module_guides/loading/ingestion_pipeline/transformations.html) to consider including \n",
    "[text splitters](https://docs.llamaindex.ai/en/v0.9.48/module_guides/loading/node_parsers/modules.html#text-splitters),\n",
    "[node parsers](https://docs.llamaindex.ai/en/v0.9.48/module_guides/loading/node_parsers/modules.html), \n",
    "and [metadata extractors](https://docs.llamaindex.ai/en/v0.9.48/module_guides/loading/documents_and_nodes/usage_metadata_extractor.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825452f6",
   "metadata": {},
   "source": [
    "**Optional Task 3** Embeddings Model\n",
    "\n",
    "Experiment further with other state of the art embeddings model and see if you can further improve the accuracy of the your Retriever (by having the better pre-processed data).\n",
    "\n",
    "The embeddings models developed by [Voyage AI](https://www.voyageai.com) are some of the best in the industry. They also provide generous free-tier use of the embeddings models (as a service). Signing-up to get a developer account is a fairly light-weight process. \n",
    "\n",
    "The benefit that you'll get is 1/ seeing how to use a whole new model family for embeddings with Llamaindex, 2/ a deeper knowledge of your embeddings options, and 3/ perhaps, a more accurate Retriever for your solution.\n",
    "\n",
    "If you prefer to try other embeddings models, such as those provided by OpenAI, that's also well worth exploring."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
